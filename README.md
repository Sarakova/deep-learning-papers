# Deep Learning Papers


## NIPS 2016

* M Andrychowicz et al. <b> Learning to Learn by Gradient Descent by Gradient Descent </b> [[arXiv]] (https://arxiv.org/abs/1606.04474)

* Jimmy Ba et al. <b> Using Fast Weights to Attend to the Recent Past </b> [[arXiv]](https://arxiv.org/abs/1610.06258)

* Konstantinos Bousmalis et al. <b> Domain Separation Networks </b> [[arXiv]](https://arxiv.org/abs/1608.06019)

* S. M. Ali Eslami et al. <b> Attend, Infer, Repeat: Fast Scene Understanding with Generative Models </b> [[arXiv]] (https://arxiv.org/abs/1603.08575)

<br>

## Generative Model 

#### Adversarial Learning

* Ian Goodfellow et al. <b>Generative Adversarial Networks</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.2661)

* Alec Radford et al. <b>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</b> (2015.11)  [[arXiv]](https://arxiv.org/abs/1511.06434)

* X Chen et al. <b>InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1606.03657)

* Junbo Zhao et al. <b>Energy-based Generative Adversarial Network</b> (2016.9) [[arXiv]](https://arxiv.org/abs/1609.03126)

* Scott Reed, Honglak Lee et al. <b>Learning What and Where to Draw</b> (2016.10) [[arXiv]](https://arxiv.org/abs/1610.02454) [[code]](https://github.com/reedscot/nips2016)

* Yaniv Taigman, Adam Polyak, Lior Wolf. <b>Unsupervised Cross-Domain Image Generation</b> (2016.11) [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=Sk2Im59ex) [[code]](https://github.com/yunjey/dtn-tensorflow)

* Anh Nguyen, Yoshua Bengio et al. <b> Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space </b> (2016.11) [[arXiv]](https://arxiv.org/abs/1612.00005)

* Ian Goodfellow. <b>NIPS 2016 Tutorial: Generative Adversarial Networks</b> (2016.12) [[arXiv]](https://arxiv.org/abs/1701.00160)

#### Pixel RNN/CNN

* Aaron van den Oord et al. <b>Pixel Recurrent Neural Networks</b> (2016.1) [[arXiv]](https://arxiv.org/pdf/1601.06759v3.pdf)

* Aaron van den Oord, Alex Graves et al. <b>Conditional Image Generation with PixelCNN Decoders</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1606.05328)

* Tim Salimans, Andrej Karpathy et al. <b>PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications</b> (2016.11) [[ICLR 2017 open review]](https://openreview.net/forum?id=BJrFC6ceg)

* lexander Kolesnikov et al. <b> Deep Probabilistic Modeling of Natural Images using a Pyramid Decomposition </b> (2016.12) [[arXiv]] (https://arxiv.org/abs/1612.08185)


#### Unclassified

* Leon A. Gatys et al. <b>A Neural Algorithm of Artistic Style</b> (2015.8) [[arXiv]](https://arxiv.org/abs/1508.06576) [[code]](https://github.com/anishathalye/neural-style)




<br>

## Sequence to Sequence Model

* Kyunghyun Cho, Yoshua Bengio et al. <b>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.1078)

* Ilya Sutskever, Oriol Vinyals, Quoc V. Le. <b>Sequence to Sequence Learning with Neural Networks</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.3215)

* Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. <b>Neural Machine Translation by Jointly Learning to Align and Translate</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.0473)

<br>

## Image Captioning

* Oriol Vinyals, Samy Bengio et al. <b>Show and Tell: A Neural Image Caption Generator</b> (2014.11) [[arXiv]](https://arxiv.org/abs/1411.4555)

* Kelvin Xu, Jimmy Ba, Yoshua Bengio et al. <b>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</b> (2015.2) [[arXiv]](https://arxiv.org/abs/1502.03044)

* Oriol Vinyals, Samy Bengio et al. <b>Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</b> (2016.9) [[arXiv]](https://arxiv.org/abs/1609.06647)

* Jiasen Lu, Richard Socher et al. <b> Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning </b> (2016.12) [[arXiv]] (https://arxiv.org/abs/1612.01887)




