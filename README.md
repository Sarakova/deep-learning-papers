# Deep Learning Papers



<br>

## Generative Model 

#### Adversarial Learning

* Ian Goodfellow et al. <b>Generative Adversarial Networks</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.2661)

* Alec Radford et al. <b>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</b> (2015.11)  [[arXiv]](https://arxiv.org/abs/1511.06434)

* X Chen et al. <b>InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1606.03657)

* Junbo Zhao et al. <b>Energy-based Generative Adversarial Network</b> (2016.9) [[arXiv]](https://arxiv.org/abs/1609.03126)

* Scott Reed, Honglak Lee et al. <b>Learning What and Where to Draw</b> (2016.10) [[arXiv]](https://arxiv.org/abs/1610.02454) [[code]](https://github.com/reedscot/nips2016)

* Yaniv Taigman, Adam Polyak, Lior Wolf. <b>Unsupervised Cross-Domain Image Generation</b> (2016.11) (ICLR 2017) [[arXiv]](https://arxiv.org/abs/1611.02200) [[code]](https://github.com/yunjey/dtn-tensorflow)

* Anh Nguyen, Yoshua Bengio et al. <b> Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space </b> (2016.11) [[arXiv]](https://arxiv.org/abs/1612.00005)

* Ian Goodfellow. <b>NIPS 2016 Tutorial: Generative Adversarial Networks</b> (2016.12) [[arXiv]](https://arxiv.org/abs/1701.00160)

#### Pixel RNN/CNN

* Aaron van den Oord et al. <b>Pixel Recurrent Neural Networks</b> (2016.1) [[arXiv]](https://arxiv.org/pdf/1601.06759v3.pdf)

* Aaron van den Oord, Alex Graves et al. <b>Conditional Image Generation with PixelCNN Decoders</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1606.05328)

* Tim Salimans, Andrej Karpathy et al. <b>PixelCNN++: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications</b> (2016.11) [[ICLR 2017 open review]](https://openreview.net/forum?id=BJrFC6ceg)

* Kolesnikov et al. <b> Deep Probabilistic Modeling of Natural Images using a Pyramid Decomposition </b> (2016.12) [[arXiv]](https://arxiv.org/abs/1612.08185)


#### Unclassified

* Leon A. Gatys et al. <b>A Neural Algorithm of Artistic Style</b> (2015.8) [[arXiv]](https://arxiv.org/abs/1508.06576) [[code]](https://github.com/anishathalye/neural-style)

<br>

## Reinforcement Learning

#### DQN 

* Mnih et al. <b>Playing Atari with Deep Reinforcement Learning</b> (2013.12) [[arXiv]](https://arxiv.org/abs/1312.5602)

* Mnih et al. <b>Human-level control through deep reinforcement learning</b> (2015.1) [[nature]](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html)

<br>

## Sequence to Sequence Model

* Kyunghyun Cho, Yoshua Bengio et al. <b>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.1078)

* Ilya Sutskever, Oriol Vinyals, Quoc V. Le. <b>Sequence to Sequence Learning with Neural Networks</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.3215)

* Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. <b>Neural Machine Translation by Jointly Learning to Align and Translate</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.0473)

* Bahdanau et al. <b>An Actor-Critic Algorithm for Sequence Prediction</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1607.07086)

<br>

## Image Captioning

* Oriol Vinyals, Samy Bengio et al. <b>Show and Tell: A Neural Image Caption Generator</b> (2014.11) [[arXiv]](https://arxiv.org/abs/1411.4555)

* Kelvin Xu, Jimmy Ba, Yoshua Bengio et al. <b>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</b> (2015.2) [[arXiv]](https://arxiv.org/abs/1502.03044)

* Oriol Vinyals, Samy Bengio et al. <b>Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</b> (2016.9) [[arXiv]](https://arxiv.org/abs/1609.06647)

* Jiasen Lu, Richard Socher et al. <b> Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning </b> (2016.12) [[arXiv]](https://arxiv.org/abs/1612.01887)

* Siqi Liu et al. <b>Improved Image Captioning via Policy Gradient optimization of SPIDEr</b> (2016.12) [[arXiv]](https://arxiv.org/abs/1612.00370)




