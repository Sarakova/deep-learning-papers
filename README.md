# Deeplearning Papers (2016.11.9 ~) 
Deep learning paper list (ongoing)


## Neural Network Model
* David Krueger et al. <b> Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations </b> (2016.11) [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=rJqBEPcxe)

* Gabriel Pereyra et al. <b> Regularizing Neural Networks by Penalizing Confident Output Distributions </b> (2016.11) [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=HkCjNI5ex)

* Yingce Xia et al. <b> Dual Learning for Machine Translation </b> (2016.11) [[arXiv]] (https://arxiv.org/abs/1611.00179)

## Optimization 

* Max Jaderberg et al. <b> Decoupled Neural Interfaces using Synthetic Gradients </b> (2016.8) [[arXiv]] (https://arxiv.org/abs/1608.05343)


## Generative Model

* Diederik P Kingma, Max Welling. <b> Auto-Encoding Variational Bayes </b> (2013.12) [[arXiv]] (https://arxiv.org/abs/1312.6114)

* Ian J. Goodfellow et al. <b> Generative Adversarial Networks </b> (2014.6) [[arXiv]] (https://arxiv.org/abs/1406.2661)

* Alec Radford, Luke Metz, Soumith Chintala. <b> Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks </b> (2015.11) [[arXiv]] (https://arxiv.org/abs/1511.06434)

* Yaniv Taigman, Adam Polyak, Lior Wolf. <b>Unsupervised Cross-Domain Image Generation</b> (2016.11) [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=Sk2Im59ex) 


## Sequence-to-Sequence Model
* Kyunghyun Cho et al. <b>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.1078) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/learning_phrase_representation_using_rnn_enc_dec.md)

* Ilya Sutskever, Oriol Vinyals, Quoc V. Le. <b> Sequence to Sequence Learning with Neural Networks.</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.3215) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/seq2seq_with_nn.md)

* Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. <b> Neural Machine Translation by Jointly Learning to Align and Translate.</b> (2014.9) [[arXiv]](https://arxiv.org/abs/1409.0473) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/nmt_by_jointly_train_align_and_translate.md)


## Image Captioning
* Oriol Vinyals et al. <b> Show and Tell: A Neural Image Caption Generator </b> (2014.11) [[arXiv]] (https://arxiv.org/abs/1411.4555) 

* Xu Kelvin et al. <b> Show, attend and tell: Neural image caption generation with visual attention". </b> (2015.2) [[arXiv]] (https://arxiv.org/abs/1502.03044) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/show_attend_and_tell.md)  [[tensorflow]] (https://github.com/yunjey/show-attend-and-tell-tensorflow)

* Oriol Vinyals et al. <b> Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge </b> (2016.9) [[arXiv]] (https://arxiv.org/abs/1609.06647) [[tensorflow]] (https://github.com/tensorflow/models/tree/master/im2txt)

## Natural Language Processing

* Iulian Vlad Serban et al. <b> Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus </b> (2016.3) [[arXiv]] (https://arxiv.org/abs/1603.06807) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/generating_factoid_questions_with_rnn.md) 


