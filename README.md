## <i>2016-12</i>

* <i>Alexander Kolesnikov, Christoph H. Lampert. <b> Pyramid Pixel CNN (state-of-the-art in image modeling)</i></b> [[arXiv]] (https://arxiv.org/abs/1612.08185)
* <i>Yann N. Dauphin et al. <b>Language Modeling with Gated Convolutional Networks </b></i>[[arXiv]] (https://arxiv.org/abs/1612.08083)
* <i> Jiasen Lu et al. <b> Knowing When to Look (state-of-the-art in image captioning)</b></i> [[arXiv]] (https://arxiv.org/abs/1612.01887)

<br>



<br>

## NIPS 2016

* M Andrychowicz et al. <b> Learning to Learn by Gradient Descent by Gradient Descent </b> (NIPS 2016) [[arXiv]] (https://arxiv.org/abs/1606.04474)

* Jimmy Ba et al. <b> Using Fast Weights to Attend to the Recent Past </b> [[arXiv]](https://arxiv.org/abs/1610.06258)

* Konstantinos Bousmalis et al. <b> Domain Separation Networks </b> [[arXiv]](https://arxiv.org/abs/1608.06019)

* S. M. Ali Eslami et al. <b> Attend, Infer, Repeat: Fast Scene Understanding with Generative Models </b> [[arXiv]] (https://arxiv.org/abs/1603.08575)

<br>

## Generative Model 

- Ian J. Goodfellow et al. <b>Generative Adversarial Networks</b> (2014.6) [[arXiv]](https://arxiv.org/abs/1406.2661)
- Alec Radford et al. <b>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</b> (2015.11)  [[arXiv]](https://arxiv.org/abs/1511.06434)

* Xi Chen et al. <b>InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</b> (2016.6) [[arXiv]](https://arxiv.org/abs/1606.03657)

* Junbo Zhao et al. <b>Energy-based Generative Adversarial Network</b> (2016.9) [[arXiv]](https://arxiv.org/abs/1609.03126)

* A Oord et al. <b>Conditional Image Generation with PixelCNN Decoders</b> () [[arXiv]]()

* <b></b> () [[arXiv]]()

* Yaniv Taigman, Adam Polyak, Lior Wolf. <b>Unsupervised Cross-Domain Image Generation</b> [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=Sk2Im59ex) 


* Pixel CNN



