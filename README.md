# Deeplearning Papers (2016.11.9 ~) 
Deep learning paper list (ongoing)

<br>

## ICLR 2017 OpenReview

* Yaniv Taigman, Adam Polyak, Lior Wolf. <b>Unsupervised Cross-Domain Image Generation</b> (2016.11) [[ICLR 2017 open review]] (http://104.155.136.4:3000/forum?id=Sk2Im59ex) 

<br>


## NIPS 2016

* Jimmy Ba et al. <b> Using Fast Weights to Attend to the Recent Past </b> (2016.10) [[arXiv]](https://arxiv.org/abs/1610.06258)

* Konstantinos Bousmalis et al. <b> Domain Separation Networks </b> (NIPS 2016) [[arXiv]] (https://arxiv.org/abs/1608.06019)
<br>

## DeepMind

* M Fraccaro et al. <b> Sequential Neural Models with Stochastic Layers </b> (NIPS 2016) [[arXiv]] (https://arxiv.org/abs/1605.07571)

* M Andrychowicz et al. <b> Learning to Learn by Gradient Descent by Gradient Descent </b> (NIPS 2016) [[arXiv]] (https://arxiv.org/abs/1606.04474)

* Max Jaderberg et al. <b> Decoupled Neural Interfaces using Synthetic Gradients </b> (2016.8) [[arXiv]] (https://arxiv.org/abs/1608.05343)

* A van den Oord et al <b> WaveNet: A Generative Model for Raw Audio </b> (2016.9) [[arXiv]] (https://arxiv.org/abs/1609.03499)

<br>


## Google Brain Team

* Amit Daniely et al. <b> Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity </b> (2016.2) [[arXiv]] (https://arxiv.org/abs/1602.05897)

* S. M. Ali Eslami et al. <b> Attend, Infer, Repeat: Fast Scene Understanding with Generative Models </b> (2016.3) [[arXiv]] (https://arxiv.org/abs/1603.08575)




<br>





## Image Captioning
* Oriol Vinyals et al. <b> Show and Tell: A Neural Image Caption Generator </b> (2014.11) [[arXiv]] (https://arxiv.org/abs/1411.4555) 

* Xu Kelvin et al. <b> Show, attend and tell: Neural image caption generation with visual attention". </b> (2015.2) [[arXiv]] (https://arxiv.org/abs/1502.03044) [[notes]] (https://github.com/yunjey/deeplearning-papers/blob/master/notes/show_attend_and_tell.md)  [[tensorflow]] (https://github.com/yunjey/show-attend-and-tell-tensorflow)

* Oriol Vinyals et al. <b> Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge </b> (2016.9) [[arXiv]] (https://arxiv.org/abs/1609.06647) [[tensorflow]] (https://github.com/tensorflow/models/tree/master/im2txt)

* Jiasen Lu et al. <b> Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning </b> (2016.12) [[arXiv]] (https://arxiv.org/abs/1612.01887)

<br>


